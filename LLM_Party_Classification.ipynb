{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPL/EmWrXfmaBAEeBmhGgy3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorenzEh/Tweet-Classification/blob/main/LLM_Party_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing libraries and basic data exploration"
      ],
      "metadata": {
        "id": "6BLGiJbN7gZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQE-taTuiVXQ",
        "outputId": "753203b2-844e-457b-f711-1e2165a1c889"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "wTb5m-UvcR8x"
      },
      "outputs": [],
      "source": [
        "from importlib.metadata import version\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = pd.read_parquet(\"hf://datasets/Jacobvs/PoliticalTweets/formatted_data.parquet\")"
      ],
      "metadata": {
        "id": "H2GWu9d9XKK1"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "K7zqX9MajPiX",
        "outputId": "9b5decac-693d-484d-b15a-2b2e70e9a6aa"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      date                   id         username  \\\n",
              "index                                                              \n",
              "0      2021-10-13 19:47:44  1448374915636383745    SenatorHassan   \n",
              "1      2021-06-30 14:53:13  1410250073003462656  SenatorMenendez   \n",
              "2      2021-08-08 01:11:29  1424176405881966599   SenBillCassidy   \n",
              "3      2021-04-14 14:02:49  1382333523567185921    SenBlumenthal   \n",
              "4      2021-12-11 16:06:38  1469700160934621188     SenatorBraun   \n",
              "5      2021-05-11 17:18:50  1392167324401143812   SenJeffMerkley   \n",
              "6      2021-08-10 16:22:55  1425130548620578816    SenBlumenthal   \n",
              "7      2021-08-12 01:13:26  1425626448518385664   SenatorHagerty   \n",
              "8      2021-12-11 16:27:51  1469705498224209928   SenBillCassidy   \n",
              "9      2021-01-20 13:55:04  1351890994220957698       CoryBooker   \n",
              "\n",
              "                                                    text       party  labels  \n",
              "index                                                                         \n",
              "0      Happy th birthday to the @USNavy! The strength...    Democrat       1  \n",
              "1      The greatest generation's investment in infras...    Democrat       1  \n",
              "2      Thanks to @SenTedCruz and  @SenatorWarnock, th...  Republican       0  \n",
              "3      / To get lasting change we cant just lock up t...    Democrat       1  \n",
              "4      Today were celebrating years of the Hoosier st...  Republican       0  \n",
              "5      The #ForthePeopleAct includes reforms that are...    Democrat       1  \n",
              "6      Todays strong, bipartisan vote is just the beg...    Democrat       1  \n",
              "7      Supporting crime victims requires holding crim...  Republican       0  \n",
              "8      We in Louisiana know how natural disasters cha...  Republican       0  \n",
              "9                                   Today we start anew.    Democrat       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b276e24b-4dce-406d-bf7c-956495e31e86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>id</th>\n",
              "      <th>username</th>\n",
              "      <th>text</th>\n",
              "      <th>party</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-10-13 19:47:44</td>\n",
              "      <td>1448374915636383745</td>\n",
              "      <td>SenatorHassan</td>\n",
              "      <td>Happy th birthday to the @USNavy! The strength...</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-06-30 14:53:13</td>\n",
              "      <td>1410250073003462656</td>\n",
              "      <td>SenatorMenendez</td>\n",
              "      <td>The greatest generation's investment in infras...</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-08-08 01:11:29</td>\n",
              "      <td>1424176405881966599</td>\n",
              "      <td>SenBillCassidy</td>\n",
              "      <td>Thanks to @SenTedCruz and  @SenatorWarnock, th...</td>\n",
              "      <td>Republican</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-04-14 14:02:49</td>\n",
              "      <td>1382333523567185921</td>\n",
              "      <td>SenBlumenthal</td>\n",
              "      <td>/ To get lasting change we cant just lock up t...</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-12-11 16:06:38</td>\n",
              "      <td>1469700160934621188</td>\n",
              "      <td>SenatorBraun</td>\n",
              "      <td>Today were celebrating years of the Hoosier st...</td>\n",
              "      <td>Republican</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-05-11 17:18:50</td>\n",
              "      <td>1392167324401143812</td>\n",
              "      <td>SenJeffMerkley</td>\n",
              "      <td>The #ForthePeopleAct includes reforms that are...</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021-08-10 16:22:55</td>\n",
              "      <td>1425130548620578816</td>\n",
              "      <td>SenBlumenthal</td>\n",
              "      <td>Todays strong, bipartisan vote is just the beg...</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2021-08-12 01:13:26</td>\n",
              "      <td>1425626448518385664</td>\n",
              "      <td>SenatorHagerty</td>\n",
              "      <td>Supporting crime victims requires holding crim...</td>\n",
              "      <td>Republican</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2021-12-11 16:27:51</td>\n",
              "      <td>1469705498224209928</td>\n",
              "      <td>SenBillCassidy</td>\n",
              "      <td>We in Louisiana know how natural disasters cha...</td>\n",
              "      <td>Republican</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2021-01-20 13:55:04</td>\n",
              "      <td>1351890994220957698</td>\n",
              "      <td>CoryBooker</td>\n",
              "      <td>Today we start anew.</td>\n",
              "      <td>Democrat</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b276e24b-4dce-406d-bf7c-956495e31e86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b276e24b-4dce-406d-bf7c-956495e31e86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b276e24b-4dce-406d-bf7c-956495e31e86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e4e3e61a-ade5-4ad8-a59c-d6b12fba8ab1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e4e3e61a-ade5-4ad8-a59c-d6b12fba8ab1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e4e3e61a-ade5-4ad8-a59c-d6b12fba8ab1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nr = 1\n",
        "print(\"Exmaple Tweet:\")\n",
        "print(dataframe[\"text\"][nr])\n",
        "print(\"Party:\")\n",
        "print(dataframe[\"party\"][nr])\n",
        "\n",
        "\n",
        "print(\"\\nFrom:\")\n",
        "print(dataframe[\"date\"].min())\n",
        "\n",
        "print(\"\\nTo:\")\n",
        "print(dataframe[\"date\"].max())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-ScxC74luSZ",
        "outputId": "9007a69d-627f-46ac-a977-7c8407c193c9"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exmaple Tweet:\n",
            "The greatest generation's investment in infrastructure made us the envy of the world. But now we've gone almost an entire lifetime without making any significant investments in the NEXT generation of American infrastructure. It's time for that to change. https://t.co/brikl79Kgp\n",
            "Party:\n",
            "Democrat\n",
            "\n",
            "From:\n",
            "2016-09-28 04:16:02\n",
            "\n",
            "To:\n",
            "2023-02-19 23:32:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation\n",
        "Data preparation involves the following steps:\n",
        "\n",
        "- Splitting the balanced dataset into training, validation, and test sets while preserving class distribution in each split. Additionally: concat the remaining tweets in a dataframe, which can be later used to check how the model behaves (additionally to the testing data).\n",
        "- Saving the split datasets to CSV files for later use.\n",
        "\n",
        "Introducing text normalization could be considered here, although it could lead to a loss of information (for example the usage of capslock for expressing hrad feelings about something)"
      ],
      "metadata": {
        "id": "UEEmrp3aFJoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we limit the dataset and make sure it has the same number of democratic and republican tweets in each datatset, we keep the remaining tweets for later\n",
        "# training the model with all the data availabe would be better, but isn't really feasible with limited ressources.\n",
        "\n",
        "def balance_and_split_dataset(df, train_frac, validation_frac, sample_size=50000, random_state=None):\n",
        "    if random_state is not None:\n",
        "        torch.manual_seed(random_state)\n",
        "\n",
        "    # first, create the balanced subset of sample_size from the original dataframe\n",
        "    democrat_df = df[df[\"party\"] == \"Democrat\"].copy()\n",
        "    republican_df = df[df[\"party\"] == \"Republican\"].copy()\n",
        "\n",
        "    min_samples = min(len(democrat_df), len(republican_df), sample_size // 2)\n",
        "    if min_samples * 2 < sample_size:\n",
        "         print(f\"Warning: Not enough samples to create a balanced dataset of size {sample_size}. Using size {min_samples * 2} instead.\")\n",
        "         sample_size = min_samples * 2\n",
        "\n",
        "    # get the original indices of the sampled tweets for the balanced subset\n",
        "    democrat_sample_indices = democrat_df.sample(n=sample_size // 2, random_state=random_state, replace=False).index\n",
        "    republican_sample_indices = republican_df.sample(n=sample_size // 2, random_state=random_state, replace=False).index\n",
        "\n",
        "    # create the balanced subset dataframe using the original indices\n",
        "    balanced_subset_indices = democrat_sample_indices.union(republican_sample_indices)\n",
        "    balanced_subset_df = df.loc[balanced_subset_indices].sample(frac=1, random_state=random_state).reset_index(drop=True) # Shuffle the balanced subset\n",
        "\n",
        "    # split the balanced subset dataframe into train, validation, and test\n",
        "    total_balanced = len(balanced_subset_df)\n",
        "    train_count = int(total_balanced * train_frac)\n",
        "    validation_count = int(total_balanced * validation_frac)\n",
        "    test_count = total_balanced - train_count - validation_count # The rest goes to test\n",
        "\n",
        "    # split the balanced subset while maintaining balance within each split\n",
        "    # separate into Democrat and Republican within the balanced subset\n",
        "    balanced_democrat_df = balanced_subset_df[balanced_subset_df[\"party\"] == \"Democrat\"].copy()\n",
        "    balanced_republican_df = balanced_subset_df[balanced_subset_df[\"party\"] == \"Republican\"].copy()\n",
        "\n",
        "    # calculate counts for each split per party\n",
        "    train_democrat_count_split = int(len(balanced_democrat_df) * train_frac)\n",
        "    validation_democrat_count_split = int(len(balanced_democrat_df) * validation_frac)\n",
        "    test_democrat_count_split = len(balanced_democrat_df) - train_democrat_count_split - validation_democrat_count_split\n",
        "\n",
        "    train_republican_count_split = int(len(balanced_republican_df) * train_frac)\n",
        "    validation_republican_count_split = int(len(balanced_republican_df) * validation_frac)\n",
        "    test_republican_count_split = len(balanced_republican_df) - train_republican_count_split - validation_republican_count_split\n",
        "\n",
        "\n",
        "    # sample for each split from the balanced subset, maintaining balance\n",
        "    train_democrat_sample = balanced_democrat_df.sample(n=train_democrat_count_split,random_state=random_state, replace=False)\n",
        "    remaining_democrat_split = balanced_democrat_df.drop(train_democrat_sample.index)\n",
        "    validation_democrat_sample = remaining_democrat_split.sample(n=validation_democrat_count_split, random_state=random_state, replace=False)\n",
        "    test_democrat_sample = remaining_democrat_split.drop(validation_democrat_sample.index).sample(n=test_democrat_count_split,\n",
        "                                                                                                  random_state=random_state, replace=False)\n",
        "\n",
        "    train_republican_sample = balanced_republican_df.sample(n=train_republican_count_split, random_state=random_state, replace=False)\n",
        "    remaining_republican_split = balanced_republican_df.drop(train_republican_sample.index)\n",
        "    validation_republican_sample = remaining_republican_split.sample(n=validation_republican_count_split, random_state=random_state, replace=False)\n",
        "    test_republican_sample = remaining_republican_split.drop(validation_republican_sample.index).sample(n=test_republican_count_split,\n",
        "                                                                                                        random_state=random_state, replace=False)\n",
        "\n",
        "\n",
        "    # combine the samples for each final split\n",
        "    train_df = pd.concat([train_democrat_sample, train_republican_sample]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "    validation_df = pd.concat([validation_democrat_sample, validation_republican_sample]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "    test_df = pd.concat([test_democrat_sample, test_republican_sample]).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "    # remaining tweets are those whose indices are not in the initial balanced subset, we keep them to test the model later\n",
        "    remaining_df = df.drop(balanced_subset_indices).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "\n",
        "    # drop unnecessary columns from all dataframes\n",
        "    train_df.drop(columns=[\"id\", \"date\", \"party\", \"username\"], inplace=True)\n",
        "    validation_df.drop(columns=[\"id\", \"date\", \"party\", \"username\"], inplace=True)\n",
        "    test_df.drop(columns=[\"id\", \"date\", \"party\", \"username\"], inplace=True)\n",
        "    remaining_df.drop(columns=[\"id\", \"date\", \"party\", \"username\"], inplace=True)\n",
        "\n",
        "    return train_df, validation_df, test_df, remaining_df\n",
        "\n",
        "train_df, validation_df, test_df, remaining_df = balance_and_split_dataset(\n",
        "    dataframe, train_frac=0.7, validation_frac=0.1, sample_size=100000, random_state=42\n",
        ")\n",
        "\n",
        "# Save the datasets\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)\n",
        "remaining_df.to_csv(\"remaining.csv\", index=None)\n",
        "\n",
        "# check if they were correctly created\n",
        "print(\"Train set distribution:\")\n",
        "print(train_df[\"labels\"].value_counts())\n",
        "\n",
        "print(\"\\nValidation set distribution:\")\n",
        "print(validation_df[\"labels\"].value_counts())\n",
        "\n",
        "print(\"\\nTest set distribution:\")\n",
        "print(test_df[\"labels\"].value_counts())\n",
        "\n",
        "print(\"\\nRemaining Tweets:\")\n",
        "print(remaining_df[\"labels\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmujgHZNT8mq",
        "outputId": "c255c1cf-892e-4a20-8a08-080436c1a3ab"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set distribution:\n",
            "labels\n",
            "0    35000\n",
            "1    35000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Validation set distribution:\n",
            "labels\n",
            "0    5000\n",
            "1    5000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test set distribution:\n",
            "labels\n",
            "0    10000\n",
            "1    10000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Remaining Tweets:\n",
            "labels\n",
            "1    47901\n",
            "0    42590\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The PrepareDataset Class does the following things:\n",
        "1. Tokenizing text inputs\n",
        "\n",
        "2. Handling variable-length sequences (padding/truncating)\n",
        "\n",
        "3. Converting data to PyTorch tensors"
      ],
      "metadata": {
        "id": "pFc5JXqD1KNs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "MdwnRDUwEOOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31784e99-f2ca-484b-aaf6-10a7d70c02a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "# we will make use of the tiktoken tokenizer\n",
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n",
        "\n",
        "class PrepareDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256): # max lenght: we artifically truncate the lenght (sometimes we dont need 1000000 tokens in a single input),\n",
        "    # Padding token ID (default=50256, GPT-2's pad token)\n",
        "        self.data = pd.read_csv(csv_file) # csv file we want to open\n",
        "        self.data[\"text\"] = self.data[\"text\"].astype(str)\n",
        "\n",
        "        # pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text)) # we fill up the lenght to the max lenght\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index] # text\n",
        "        label = self.data.iloc[index][\"labels\"] # zero or one\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long), # we convert to tensors\n",
        "            torch.tensor(label, dtype=torch.long) # we convert to tensors\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self): # find the longest sequence.\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = PrepareDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length) # longest message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MebHM8yZ10QK",
        "outputId": "40f9834a-1ae1-4c4a-b7ba-4113e7891135"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = PrepareDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length, # pad text to the length of the training dataset\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "test_dataset = PrepareDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "oznhqnMHVzgB"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the datsets into the pytorch DataLoader. It serves as utility tool to do the following things:\n",
        "\n",
        "- Batching: Groups individual sequences into batches (e.g., 8/16/32 samples per batch)\n",
        "- Shuffling: Randomizes sample order (critical for training to avoid order bias)\n",
        "- Parallel Loading: Uses multiple workers (`num_workers`) to load data concurrently. Basically it means that while the model is preprocessing (eg. tokenization and padding) the current batch on the GPU, it can start preprocessing the next batch already (parallel).\n",
        "- Memory Management\t: Preloads data into memory buffers for faster access (via prefetching)\n",
        "- Handling Edge Cases: Drops or keeps the last incomplete batch (`drop_last=True/False`)\n"
      ],
      "metadata": {
        "id": "fEnRyV3dKQZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "LQ09zlQ7GB93"
      },
      "outputs": [],
      "source": [
        "num_workers = 2\n",
        "batch_size = 32\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    drop_last=False, # preserve all data for evaluation\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        "    drop_last=False,  # preserve all data for evaluation\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train loader:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"Input batch dimensions:\", input_batch.shape)\n",
        "print(\"Label batch dimensions\", target_batch.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Dg_3k4vZf3c",
        "outputId": "96903693-a9c0-44d5-912f-f88574576cff"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loader:\n",
            "Input batch dimensions: torch.Size([32, 169])\n",
            "Label batch dimensions torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# how many batches do we have in each dataset?\n",
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKv_WZDAZnAV",
        "outputId": "321d920d-4739-4f35-b5c5-5dccd76bff05"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2187 training batches\n",
            "313 validation batches\n",
            "625 test batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "lc-5ORkKG9IA"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\" # we use the smallest model, to minimze the lenght of the training\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size, GPT-2's vocabulary size (50,257 tokens)\n",
        "    \"context_length\": 1024,  # Context length, maximum sequence lenght the model can process about 2 pages of text\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "# \"safety\" check:\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
        "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
        "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the model\n",
        "\n",
        "This part was taken from Sebastian Raschka's video tutorial ([Youtube](https://www.youtube.com/watch?v=4yNswvhPWCQ&list=PLTKMiZHVd_2IIEsoJrWACkIxLRdfMlw11) & [Github](https://github.com/rasbt/LLMs-from-scratch)) and remained largely untouched.\n",
        "\n",
        "I choose to work with the smallest model, as larger models take too much ressources and time to train (I have limited Colab ressources)."
      ],
      "metadata": {
        "id": "SIOV7gm6Kncv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next block we are writing functions for the following two things:\n",
        "\n",
        "1. We download and load gpt2 (`download_and_load_gpt2` & `download_file`)\n",
        "2. We convert tensorflow checkpoints to pytorch-style nested dictionaries (`load_gpt2_params_from_tf_ckpt`)"
      ],
      "metadata": {
        "id": "IbT9NMKkQuA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    backup_base_url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/gpt2\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        backup_url = os.path.join(backup_base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        download_file(file_url, file_path, backup_url)\n",
        "\n",
        "    # Load settings and params\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\"), \"r\", encoding=\"utf-8\"))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "\n",
        "def download_file(url, destination, backup_url=None):\n",
        "    def _attempt_download(download_url):\n",
        "        with urllib.request.urlopen(download_url) as response:\n",
        "            # Get the total file size from headers, defaulting to 0 if not present\n",
        "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
        "\n",
        "            # Check if file exists and has the same size\n",
        "            if os.path.exists(destination):\n",
        "                file_size_local = os.path.getsize(destination)\n",
        "                if file_size == file_size_local:\n",
        "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
        "                    return True  # Indicate success without re-downloading\n",
        "\n",
        "            block_size = 1024  # 1 Kilobyte\n",
        "\n",
        "            # Initialize the progress bar with total file size\n",
        "            progress_bar_description = os.path.basename(download_url)\n",
        "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
        "                with open(destination, \"wb\") as file:\n",
        "                    while True:\n",
        "                        chunk = response.read(block_size)\n",
        "                        if not chunk:\n",
        "                            break\n",
        "                        file.write(chunk)\n",
        "                        progress_bar.update(len(chunk))\n",
        "            return True\n",
        "\n",
        "    try:\n",
        "        if _attempt_download(url):\n",
        "            return\n",
        "    except (urllib.error.HTTPError, urllib.error.URLError):\n",
        "        if backup_url is not None:\n",
        "            print(f\"Primary URL ({url}) failed. Attempting backup URL: {backup_url}\")\n",
        "            try:\n",
        "                if _attempt_download(backup_url):\n",
        "                    return\n",
        "            except urllib.error.HTTPError:\n",
        "                pass\n",
        "\n",
        "        # If we reach here, both attempts have failed\n",
        "        error_message = (\n",
        "            f\"Failed to download from both primary URL ({url})\"\n",
        "            f\"{' and backup URL (' + backup_url + ')' if backup_url else ''}.\"\n",
        "            \"\\nCheck your internet connection or the file availability.\\n\"\n",
        "            \"For help, visit: https://github.com/rasbt/LLMs-from-scratch/discussions/273\"\n",
        "        )\n",
        "        print(error_message)\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    \"\"\"\n",
        "    This function brigdes the gap between the pre-trained GPT-2 weights, which are stored in a TensorFlow checkpoint,\n",
        "    and my recreated PyTorch model.\n",
        "\n",
        "    It essentially loads the parameters (weights and biases) from the TensorFlow checkpoint and\n",
        "    converts them into a format suitable for your PyTorch model.\n",
        "    \"\"\"\n",
        "    # Initialize parameters dictionary with empty blocks for each layer\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Iterate over each variable in the checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        # Load the variable and remove singleton dimensions\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process the variable name to extract relevant parts\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
        "\n",
        "        # Identify the target dictionary for the variable\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        # Recursively access or create nested dictionaries\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        # Assign the variable array to the last key\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params"
      ],
      "metadata": {
        "id": "X2l7BsbbZ5kr"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recreating the GPT-2 Architecture\n",
        "\n",
        "This implementation is based on Sebastian Raschkas video series and remains largely untouched. It provides a clear, modular breakdown of the GPT-2 architecture.\n",
        "\n",
        "## 1. `MultiHeadAttention(nn.Module)`\n",
        "**The core self-attention mechanism.**\n",
        "\n",
        "It enables the model to \"understand\" a word in context by attending to other words in the sequence.\n",
        "\n",
        "- Projects inputs into **Queries**, **Keys**, and **Values**\n",
        "- Splits each projection into multiple heads  parallel attention mechanisms\n",
        "- Computes attention scores using **scaled dot-product attention**\n",
        "- Applies a **causal mask** to prevent attending to future tokens (autoregressive property)\n",
        "- Combines the multi-head outputs into a final **context vector**\n",
        "\n",
        "\n",
        "## 2. `LayerNorm(nn.Module)`\n",
        "**Stabilizes training and improves convergence.**\n",
        "\n",
        "- Normalizes input across the **embedding dimension**\n",
        "- Similar to z-standardization, but with **learnable scale and shift parameters**\n",
        "- Ensures consistent input distributions throughout the network\n",
        "\n",
        "\n",
        "## 3. `GELU(nn.Module)`\n",
        "**Activation function used instead of ReLU.**\n",
        "\n",
        "- Applies a **Gaussian-weighted nonlinearity**\n",
        "- Smooth and differentiable  better empirical performance in transformers\n",
        "- Introduces a **probabilistic behavior** helpful for language modeling\n",
        "\n",
        "## 4. `FeedForward(nn.Module)`\n",
        "**A position-wise fully connected feedforward network.**\n",
        "\n",
        "- Operates independently on each token\n",
        "- Increases depth and modeling capacity beyond self-attention\n",
        "- Architecture:  \n",
        "  `Linear (emb_dim  4emb_dim)`  `GELU()`  `Linear (4emb_dim  emb_dim)`\n",
        "\n",
        "## 5. `TransformerBlock(nn.Module)`\n",
        "**Combines attention and feedforward sublayers with residuals and normalization.**\n",
        "\n",
        "- LayerNorm  MultiHeadAttention  Residual Connection  \n",
        "- LayerNorm  FeedForward  Residual Connection  \n",
        "- Includes dropout for regularization\n",
        "\n",
        "## 6. `GPTModel(nn.Module)`\n",
        "**The full GPT-2 model.**\n",
        "\n",
        "- Token embedding + Positional embedding\n",
        "- A stack of `n` TransformerBlocks\n",
        "- Final LayerNorm\n",
        "- Output projection layer to vocabulary size for logits (will later be changed for classification)\n",
        "\n"
      ],
      "metadata": {
        "id": "LmPhEM_W_73R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim, head dimension is the dimension of the context vector before we concatinate them\n",
        "\n",
        "        # we have bigger matrices, which we will then split\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim) # we are splitting the matrix\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "class LayerNorm(nn.Module): # layer normalization\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim)) # per default 1\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim)) # per default 0\n",
        "\n",
        "    def forward(self, x): # normalization (value - mean divided by std deviation)\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        # this is new: shift = 0, but during the training the network learns values which are better for normalization\n",
        "        return self.scale * norm_x + self.shift # per default 1 * norm_x + 0 (nothing happens per default)\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh( # this is just the maths of the gelu function...\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # we have a linear layer\n",
        "            GELU(),                                        # a GELU layer\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # again a linear layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "NMcifhvNbDQp"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following function is used to load the pre-trained weights into our custom built GPT-2 architecture."
      ],
      "metadata": {
        "id": "8NrI0vETquce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def assign(left, right):\n",
        "    if left.shape != right.shape:\n",
        "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
        "    return torch.nn.Parameter(torch.tensor(right))\n",
        "\n",
        "def load_weights_into_gpt(gpt, params):\n",
        "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
        "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
        "\n",
        "    for b in range(len(params[\"blocks\"])):\n",
        "        q_w, k_w, v_w = np.split( # we need to split the qkv matrix into the indivdual matrices (gpt uses a single matrix for qkv, but we want singe matrices)\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
        "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
        "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
        "\n",
        "        q_b, k_b, v_b = np.split(\n",
        "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
        "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
        "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
        "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
        "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
        "\n",
        "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.weight,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
        "            gpt.trf_blocks[b].att.out_proj.bias,\n",
        "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[0].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
        "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].weight,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
        "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
        "            gpt.trf_blocks[b].ff.layers[2].bias,\n",
        "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
        "\n",
        "        gpt.trf_blocks[b].norm1.scale = assign(\n",
        "            gpt.trf_blocks[b].norm1.scale,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm1.shift = assign(\n",
        "            gpt.trf_blocks[b].norm1.shift,\n",
        "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
        "        gpt.trf_blocks[b].norm2.scale = assign(\n",
        "            gpt.trf_blocks[b].norm2.scale,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
        "        gpt.trf_blocks[b].norm2.shift = assign(\n",
        "            gpt.trf_blocks[b].norm2.shift,\n",
        "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
        "\n",
        "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
        "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
        "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n"
      ],
      "metadata": {
        "id": "3WunODPSbrSw"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDoyumGXIg0q",
        "outputId": "4ef09d76-21d3-4ac9-8c19-6488c46e9136"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
            "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
            "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
            "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
            "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
          ]
        }
      ],
      "source": [
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\") # we're downloading the smallest base model, as the other ones take ages to load\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lets see how the model behaves using it as chatbot\n",
        "We just check how the model behaves as a \"simple\" chatbot. We do this before we change the output layer."
      ],
      "metadata": {
        "id": "e98PB0zh-USm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "  for _ in range(max_new_tokens):\n",
        "      # Crop current context if it exceeds the supported context size\n",
        "      # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "      # then only the last 5 tokens are used as context\n",
        "      idx_cond = idx[:, -context_size:]\n",
        "\n",
        "      # Get the predictions\n",
        "      with torch.no_grad():\n",
        "          logits = model(idx_cond)\n",
        "\n",
        "      # Focus only on the last time step\n",
        "      # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "      logits = logits[:, -1, :]\n",
        "\n",
        "      # Apply softmax to get probabilities\n",
        "      probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "      # Get the idx of the vocab entry with the highest probability value\n",
        "      idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "      # Append sampled index to the running sequence\n",
        "      idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "  return idx"
      ],
      "metadata": {
        "id": "DCHFFg6pZx6z"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwsdIJoWInDr",
        "outputId": "293c4fd1-d8ff-4887-f267-524d19ac3d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm someone who likes to play with my friends and I'm not going to let them get away with\n"
          ]
        }
      ],
      "source": [
        "text_1 = \"I'm someone who likes to\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exchanging the output layer for classification\n",
        "\n",
        "We change the output layer to be effective for classification tasks. As we only want to know, if the tweet is from an democrat or an republican we only need 2 `out_features`."
      ],
      "metadata": {
        "id": "uTYWexpq-iiP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzGqVuu_K7bd",
        "outputId": "3e78b564-96ad-4df5-99cb-d5ab14754f4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "zXmFWB0iM8kV"
      },
      "outputs": [],
      "source": [
        " # basically we're replacing the last few lines from the print statement above\n",
        " for param in model.parameters():\n",
        "    param.requires_grad = False # freezing model weights, so that they dont get updated, we're freezing the whole model parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "d39pXQV2OFjC"
      },
      "outputs": [],
      "source": [
        "# we replace the output head, which will be trainable!\n",
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Sequential(\n",
        "    torch.nn.LayerNorm(BASE_CONFIG[\"emb_dim\"]),  # normalize embeddings first\n",
        "    torch.nn.Linear(BASE_CONFIG[\"emb_dim\"], 256),  # add hidden dimension\n",
        "    torch.nn.GELU(),  # use GELU\n",
        "    torch.nn.Dropout(p=0.3),  # we add dropout to prevent the model from relying too heavily on specific neurons.\n",
        "    torch.nn.Linear(256, num_classes)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model) # only two output features (...)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT__yeOPlurk",
        "outputId": "68b4c55d-1800-447a-d7d4-9c7fe90d275b"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Sequential(\n",
            "    (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=768, out_features=256, bias=True)\n",
            "    (2): GELU(approximate='none')\n",
            "    (3): Dropout(p=0.3, inplace=False)\n",
            "    (4): Linear(in_features=256, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We freeze all transformer blocks besides the output layer some of the last blocks. We do this because the first layers usually contain basic knowledge of speech. Additionally, we need to keep our limited ressources in mind"
      ],
      "metadata": {
        "id": "X2V2TyvXeH65"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "LATD0tVGOda_"
      },
      "outputs": [],
      "source": [
        "# only last 2 tranformer blocks and output layer are trainable\n",
        "\n",
        "for param in model.trf_blocks[-2:].parameters(): # try with only 1 head\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How well is the model doing?\n",
        "In the next few cells, we just want to know how the model is behaving with regards to the data and its classification task. Therefore we use a few (modified) functions:\n",
        "\n",
        "1.   `calc_accuracy_loader`: Calculates the classification accuracy of the model\n",
        "\n",
        "\n",
        "\n",
        "2.   `calc_loss_batch`: Calculates the loss for a single batch of data during the training or evaluation process.\n",
        "\n",
        "\n",
        "\n",
        "3.   `calc_loss_loader`: uses `calc_loss_batch` internally to calculate loss over 5 batches (can be adjustes with `num_batches`)\n",
        "\n"
      ],
      "metadata": {
        "id": "lbMFipTZQu8H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "zyIDgKHSSd0j"
      },
      "outputs": [],
      "source": [
        "# we introduce mixed precision training\n",
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            # modified with mixed precision and inference mode\n",
        "            with torch.inference_mode(), autocast(device_type='cuda', dtype=torch.float16):\n",
        "                logits = model(input_batch)[:, -1, :]\n",
        "\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASdwEFCkTlOA",
        "outputId": "364b2d5b-6838-46ba-dd64-4afa5aa67d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 52.19%\n",
            "Validation accuracy: 51.56%\n",
            "Test accuracy: 53.12%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n",
        "\n",
        "# right now, our accuracy isnt that great (...), we have about 56%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "JwmSmosCVYrc"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "    # Add mixed precision context\n",
        "    with torch.inference_mode(), autocast(device_type='cuda', dtype=torch.float16):\n",
        "        logits = model(input_batch)[:, -1, :]\n",
        "        loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "\n",
        "    num_batches = min(num_batches, len(data_loader)) if num_batches else len(data_loader)\n",
        "\n",
        "    # Add inference mode and mixed precision\n",
        "    model.eval()\n",
        "    with torch.inference_mode(), autocast(device_type='cuda', dtype=torch.float16):\n",
        "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "            if i < num_batches:\n",
        "                loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "                total_loss += loss.item()\n",
        "            else:\n",
        "                break\n",
        "    return total_loss / num_batches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cjjOg2PWCsL",
        "outputId": "cf781b4b-c3e0-4809-c231-8bcfaf29d4d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 0.682\n",
            "Validation loss: 0.699\n",
            "Test loss: 0.689\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actual fine-tuning of the model\n",
        "Here are some considerations and techniques for fine-tuning the model:\n",
        "\n",
        "*   **Use a different GPT-2 model:**\n",
        "    *   **Bigger model:** Can represent more political language and deeper contextual clues, such as sarcasm, historical events/references. They generally have a stronger general understanding of language and perform better on complex language/tweets.\n",
        "    *   **Smaller model:** Needs less data. Larger models might overfit more easily on small datasets. Also, they need less computational resources (this is especially important, since we're limited by Colabs ressources). They can be less dependent on hyperparameters (learning rates, weight decay, etc.).\n",
        "*   **Change epochs:** Too many epochs can lead to overfitting; the model will then perform poorly on unseen data.\n",
        "*   **Use more tweets:** Overall better. The model is less likely to overfit on too few tweets and will learn more robust democratic and republican linguistic patterns.\n",
        "*   **Unfreeze some layers:** Can be beneficial when using more data. The model learns better to \"adapt\" to political language but also will forget some things.\n",
        "*   **Early Stopping:** Regularization technique. During training, you monitor the performance on the validation dataset. If the performance on the validation set starts to degrade (e.g., the validation loss increases or validation accuracy decreases) for a certain number of consecutive epochs, you stop the training process early, even if the model's performance on the training data is still improving.\n",
        "*   **Gradient Clipping:** Prevents \"exploding gradients\" (gradients represent the direction and magnitude of the change in the model's parameters (weights and biases) that minimizes the loss function via gradient descent). It occurs when the gradients become excessively large during backpropagation. This can lead to unstable training. Might be especially important when unfreezing some layers.\n",
        "*   **Change learning rate:** Higher rates lead to faster convergence but risk overshooting optimal weights. A lower learning rate is slower but safer.\n",
        "*   **Change weight decay:** Another kind of regularization; it penalizes large weights to prevent overfitting. Higher values lead to stronger regularization and a simpler model (risk of underfitting). Larger values might lead to overfitting.\n",
        "\n"
      ],
      "metadata": {
        "id": "hQzIWyk-TI0a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "57N2BsqaWrrb"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "cuDNN Auto-Tuner: Optimizes convolution algorithms for your specific input sizes/GPU\n",
        "TF32 Math: Uses tensor float-32 format for matrix multiplications (1.8x faster than FP32 on T4)\n",
        "Mixed Precision: Enabled via autocast and GradScaler\n",
        "\"\"\"\n",
        "torch.backends.cudnn.benchmark = True  # enable cuDNN auto-tuner\n",
        "torch.set_float32_matmul_precision('high')  # enable TF32 math\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, scheduler, device, num_epochs, # Added scheduler parameter\n",
        "                            eval_freq, eval_iter):\n",
        "\n",
        "    scaler = GradScaler()  # mixed precision training (new)\n",
        "    # Initialize lists to track losses and examples seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], [] # tracking the accurarcies and losses (... )\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            # forward pass with mixed precision\n",
        "            with autocast(device_type='cuda', dtype=torch.float16):\n",
        "                # Get the predictions\n",
        "                logits = model(input_batch)[:, -1, :]\n",
        "                # Compute loss *outside* the autocast block to ensure grad_fn\n",
        "                # loss = torch.nn.functional.cross_entropy(logits, target_batch) # Move loss calculation\n",
        "\n",
        "            # backward pass\n",
        "            # Compute loss after autocast to ensure gradient tracking\n",
        "            loss = torch.nn.functional.cross_entropy(logits, target_batch) # Moved loss calculation here\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            scheduler.step()\n",
        "\n",
        "            examples_seen += input_batch.shape[0]\n",
        "            global_step += 1\n",
        "\n",
        "            if global_step % eval_freq == 0:\n",
        "                # add mixed precision to evaluation\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    # Change from torch.no_grad() to torch.inference_mode()\n",
        "    with torch.inference_mode(), autocast(device_type='cuda', dtype=torch.float16):  # added autocast\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of batches in validation set: {len(val_loader)}\")\n",
        "print(f\"Number of batches in training set: {len(train_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldexzqXHbQ3V",
        "outputId": "1a6eaf05-4c46-464b-8b91-a19dda2809ed"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in validation set: 313\n",
            "Number of batches in training set: 2187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RZj5dQ2YqWS",
        "outputId": "6fdc25aa-d456-44ad-a726-1360b1d5ace2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 0.696, Val loss 0.699\n",
            "Ep 1 (Step 001093): Train loss 0.562, Val loss 0.575\n",
            "Ep 1 (Step 002186): Train loss 0.450, Val loss 0.468\n",
            "Training accuracy: 77.34% | Validation accuracy: 76.36%\n",
            "Ep 2 (Step 003279): Train loss 0.402, Val loss 0.428\n",
            "Ep 2 (Step 004372): Train loss 0.368, Val loss 0.413\n",
            "Training accuracy: 81.59% | Validation accuracy: 79.75%\n",
            "Ep 3 (Step 005465): Train loss 0.346, Val loss 0.402\n",
            "Ep 3 (Step 006558): Train loss 0.303, Val loss 0.391\n",
            "Training accuracy: 85.86% | Validation accuracy: 81.48%\n",
            "Training completed in 6.49 minutes.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "import time\n",
        "import torch\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "# Filter the specific UserWarning related to the scheduler step order\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.optim.lr_scheduler\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# adjust learning rate and weight decay:\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "total_steps = num_epochs * len(train_loader)\n",
        "warmup_steps = int(0.1 * total_steps)  # 10% warmup\n",
        "\n",
        "scheduler = LambdaLR(\n",
        "    optimizer,\n",
        "    lr_lambda=lambda step: min(1.0, step / warmup_steps)\n",
        ")\n",
        "\n",
        "\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=device,\n",
        "    num_epochs=num_epochs,\n",
        "    eval_freq=len(train_loader) // 2, #potential for optimization here\n",
        "    eval_iter=200 # and here\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the fine-tuning\n",
        "\n",
        "The steps after preparing the data and setting up the training parameters are focused on:\n",
        "\n",
        "*   **Visualizing training progress:** Plotting the training and validation loss and accuracy over epochs to understand model performance.\n",
        "*   **Evaluating the final model:** Assessing the trained model's performance on the unseen test set to get an unbiased evaluation. We not only use the testing data from the split, but also the remaining data for the evaluation."
      ],
      "metadata": {
        "id": "QR0tFyPjUSY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "vuspGPojYqv5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for examples seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "tjITZ2EOf9q1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "a27d5c46-a1ad-4973-c46e-2a0fde410f75"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)\n",
        "# graph looks good, it should fall steeply and then flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "FjXfZTv_f_FF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "b0bbd278-4794-4fa6-966f-1a63db305a1a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "UjnBdfFvgERV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdf4b868-a260-49f0-91f1-dfc09f10de10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 85.89%\n",
            "Validation accuracy: 81.54%\n",
            "Test accuracy: 81.84%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "PeAi7HlPgaR6"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad(): # we're not training anymore (...)\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"democrat\" if predicted_label == 1 else \"republican\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "dkClu6kwhDap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4465488-7689-44d2-f7a2-b7ca65be674b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "republican\n",
            "democrat\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\"Many Immigrants are criminals\")\n",
        "print(classify_review(text_1, model, tokenizer, device, max_length=train_dataset.max_length))\n",
        "\n",
        "text_2 = (\"Universal healthcare is needed\")\n",
        "print(classify_review(text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_3 = (\"Trump is a great president\")\n",
        "print(classify_review(text_3, model, tokenizer, device, max_length=train_dataset.max_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mhd6woFXRrbX",
        "outputId": "d567183c-caa7-471e-e68f-1a9bfa3ea14b"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "republican\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Important obersvation: The model is not very good at identifying \"casual\" texts, it's really optimized towards the poltical tweets!"
      ],
      "metadata": {
        "id": "IeEhFIZ7hTIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_tweets(df, model, tokenizer, device, max_length=169, pad_token_id=50256, num_tweets=None):\n",
        "    # Ensure model is in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Create copies to avoid modifying original dataframe\n",
        "    results = df.copy()\n",
        "\n",
        "    # Limit number of tweets if specified\n",
        "    if num_tweets is not None:\n",
        "        results = results.head(num_tweets)  # Use .sample() instead of .head() for random selection\n",
        "\n",
        "    # Convert labels to human-readable strings if needed (assuming 0=republican, 1=democrat)\n",
        "    if results['labels'].dtype != object:\n",
        "        results['actual'] = results['labels'].apply(lambda x: \"democrat\" if x == 1 else \"republican\")\n",
        "    else:\n",
        "        results['actual'] = results['labels']\n",
        "\n",
        "    # Classify tweets\n",
        "    results['predicted'] = results['text'].apply(\n",
        "        lambda x: classify_review(\n",
        "            text=x,\n",
        "            model=model,\n",
        "            tokenizer=tokenizer,\n",
        "            device=device,\n",
        "            max_length=max_length,\n",
        "            pad_token_id=pad_token_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = (results['predicted'] == results['actual']).mean()\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    conf_matrix = pd.crosstab(results['actual'], results['predicted'],\n",
        "                            rownames=['Actual'], colnames=['Predicted'])\n",
        "\n",
        "    # Calculate class-wise metrics\n",
        "    report = classification_report(results['actual'], results['predicted'])\n",
        "\n",
        "    return results, accuracy, conf_matrix, report"
      ],
      "metadata": {
        "id": "AjBu33PkW5T5"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage example:\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Run evaluation\n",
        "results_df, accuracy, conf_matrix, report = evaluate_tweets(\n",
        "    df=remaining_df,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    num_tweets=100\n",
        ")\n",
        "\n",
        "# Print results\n",
        "print(f\"Model Accuracy: {accuracy:.2%}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ-XhAqDW8ZR",
        "outputId": "10a0f928-f4f8-4e8f-8183-09fc65c82665"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 77.00%\n",
            "\n",
            "Confusion Matrix:\n",
            "Predicted   democrat  republican\n",
            "Actual                          \n",
            "democrat          41          14\n",
            "republican         9          36\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    democrat       0.82      0.75      0.78        55\n",
            "  republican       0.72      0.80      0.76        45\n",
            "\n",
            "    accuracy                           0.77       100\n",
            "   macro avg       0.77      0.77      0.77       100\n",
            "weighted avg       0.78      0.77      0.77       100\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Show some misclassified examples\n",
        "misclassified = results_df[results_df['predicted'] != results_df['actual']]\n",
        "print(f\"\\nSample of {min(10, len(misclassified))} misclassified tweets:\")\n",
        "for idx, row in misclassified.head(10).iterrows():\n",
        "    print(f\"\\nTweet: {row['text']}\")\n",
        "    print(f\"Actual: {row['actual']}, Predicted: {row['predicted']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfoNyrCAXAwo",
        "outputId": "b80154f2-d495-467d-8c16-bfec713c3de1"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample of 10 misclassified tweets:\n",
            "\n",
            "Tweet: The Commonwealth is receiving another $3,457,425.36 from the .@fema to cover costs of responding to the COVID-19 pa https://t.co/RGnQsDpEJw\n",
            "Actual: democrat, Predicted: republican\n",
            "\n",
            "Tweet: MT's extreme drought conditions are threatening the livelihoods of rural MT communities and  devastating MT ag operations. @RepRosendale and I are pushing @JoeBiden to allow grazing within the Charles M. Russell Wildlife Refuge to help relieve our ranchers and landscapes.\n",
            "Actual: republican, Predicted: democrat\n",
            "\n",
            "Tweet: Pleased to present the 2022 Congressional Fire and Rescue and Emergency Medical Services (EMS) Awards to 14 of our https://t.co/CpjvsJYzBr\n",
            "Actual: republican, Predicted: democrat\n",
            "\n",
            "Tweet: House Republicans are committed to protecting and strengthening Social Security for current beneficiaries and futur https://t.co/uDSNY0pjXD\n",
            "Actual: republican, Predicted: democrat\n",
            "\n",
            "Tweet: Unacceptable. Numerous Senators working to fix this as we speak. I just got off the phone with the acting Capitol Police Chief who insists there was no general request for the Guard to vacate the building. But whatever happened, they are working to fix the problem now. https://t.co/dR5LQvN1UF\n",
            "Actual: democrat, Predicted: republican\n",
            "\n",
            "Tweet: When you hear people refer to crisis at our border, think about this chart. Even though we have more border agents, more barrier, and better technology, illegal crossings today are near a year low. https://t.co/IoNjrqhy0R\n",
            "Actual: democrat, Predicted: republican\n",
            "\n",
            "Tweet: Just over a year ago, I was fortunate enough to join members of the 9/11 National Memorial Trail Alliance for the S https://t.co/QvNHEUsNjV\n",
            "Actual: republican, Predicted: democrat\n",
            "\n",
            "Tweet: .@SpaceForceCSO is right the U.S. must lead in establishing international norms and stability in space. As threats and competition in space continue to grow, we cannot afford to squander time, talent, or money. https://t.co/GYK05ZozE5\n",
            "Actual: democrat, Predicted: republican\n",
            "\n",
            "Tweet: More jobs\n",
            "Lower unemployment rate\n",
            "Lower uninsured rate\n",
            "Lower gas prices\n",
            "\n",
            "This is government doing what it's sup https://t.co/K0fXUkiZ2M\n",
            "Actual: democrat, Predicted: republican\n",
            "\n",
            "Tweet: It was 81 years ago today that our country was attacked at Pearl Harbor, and the course of our nations history was https://t.co/nPqTyMUFhG\n",
            "Actual: democrat, Predicted: republican\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/tweet_party_classifier.pth\"\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "34pTjlK38VVc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "db265a2a-7b37-4b29-e7da-b6e25e5ae72a"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-07a30675b917>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/tweet_party_classifier.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    }
  ]
}